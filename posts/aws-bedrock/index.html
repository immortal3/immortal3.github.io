<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>AWS BedRock - Converse API - A single endpoint for all models ? | Dip&#39;Blog</title>
<meta name="keywords" content="llm, ai">
<meta name="description" content="Amazon Bedrock is a fully managed service that makes high-performing foundation models (FMs) from leading AI startups and Amazon available for your use through a unified API. You can choose from a wide range of foundation models to find the model that is best suited for your use case. Amazon Bedrock also offers a broad set of capabilities to build generative AI applications with security, privacy, and responsible AI. With Amazon Bedrock, you can easily experiment with and evaluate top foundation models for your use cases, privately customize them with your data using techniques such as fine-tuning and Retrieval Augmented Generation (RAG), and build agents that execute tasks using your enterprise systems and data sources.">
<meta name="author" content="
Author:
Dipkumar Patel">
<link rel="canonical" href="https://dipkumar.dev/posts/aws-bedrock/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.9a3a9b6cc85cc3f62d3346fcc6d5b9344945ceca05719846bfd9d1f7a39acc84.css" integrity="sha256-mjqbbMhcw/YtM0b8xtW5NElFzsoFcZhGv9nR96OazIQ=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://dipkumar.dev/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://dipkumar.dev/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://dipkumar.dev/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://dipkumar.dev/apple-touch-icon.png">
<link rel="mask-icon" href="https://dipkumar.dev/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://dipkumar.dev/posts/aws-bedrock/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  

<meta property="og:title" content="AWS BedRock - Converse API - A single endpoint for all models ?" />
<meta property="og:description" content="Amazon Bedrock is a fully managed service that makes high-performing foundation models (FMs) from leading AI startups and Amazon available for your use through a unified API. You can choose from a wide range of foundation models to find the model that is best suited for your use case. Amazon Bedrock also offers a broad set of capabilities to build generative AI applications with security, privacy, and responsible AI. With Amazon Bedrock, you can easily experiment with and evaluate top foundation models for your use cases, privately customize them with your data using techniques such as fine-tuning and Retrieval Augmented Generation (RAG), and build agents that execute tasks using your enterprise systems and data sources." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://dipkumar.dev/posts/aws-bedrock/" />
<meta property="og:image" content="https://dipkumar.dev/images/papermod-cover.png" />
<meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-06-13T23:15:53+05:30" />
<meta property="article:modified_time" content="2024-06-13T23:15:53+05:30" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://dipkumar.dev/images/papermod-cover.png" />
<meta name="twitter:title" content="AWS BedRock - Converse API - A single endpoint for all models ?"/>
<meta name="twitter:description" content="Amazon Bedrock is a fully managed service that makes high-performing foundation models (FMs) from leading AI startups and Amazon available for your use through a unified API. You can choose from a wide range of foundation models to find the model that is best suited for your use case. Amazon Bedrock also offers a broad set of capabilities to build generative AI applications with security, privacy, and responsible AI. With Amazon Bedrock, you can easily experiment with and evaluate top foundation models for your use cases, privately customize them with your data using techniques such as fine-tuning and Retrieval Augmented Generation (RAG), and build agents that execute tasks using your enterprise systems and data sources."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://dipkumar.dev/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "AWS BedRock - Converse API - A single endpoint for all models ?",
      "item": "https://dipkumar.dev/posts/aws-bedrock/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "AWS BedRock - Converse API - A single endpoint for all models ?",
  "name": "AWS BedRock - Converse API - A single endpoint for all models ?",
  "description": "Amazon Bedrock is a fully managed service that makes high-performing foundation models (FMs) from leading AI startups and Amazon available for your use through a unified API. You can choose from a wide range of foundation models to find the model that is best suited for your use case. Amazon Bedrock also offers a broad set of capabilities to build generative AI applications with security, privacy, and responsible AI. With Amazon Bedrock, you can easily experiment with and evaluate top foundation models for your use cases, privately customize them with your data using techniques such as fine-tuning and Retrieval Augmented Generation (RAG), and build agents that execute tasks using your enterprise systems and data sources.",
  "keywords": [
    "llm", "ai"
  ],
  "articleBody": "Amazon Bedrock is a fully managed service that makes high-performing foundation models (FMs) from leading AI startups and Amazon available for your use through a unified API. You can choose from a wide range of foundation models to find the model that is best suited for your use case. Amazon Bedrock also offers a broad set of capabilities to build generative AI applications with security, privacy, and responsible AI. With Amazon Bedrock, you can easily experiment with and evaluate top foundation models for your use cases, privately customize them with your data using techniques such as fine-tuning and Retrieval Augmented Generation (RAG), and build agents that execute tasks using your enterprise systems and data sources. [1]\nAWS BedRock’s Converse API is a single endpoint that allows you to chat with any model. Indeed, the single endpoint is, I believe, the best feature of AWS BedRock. Let’s visit this endpoint and see how it works.\nmodel_id = \"anthropic.claude-3-sonnet-20240229-v1:0\" inference_config = {\"temperature\": 0.5} additional_model_fields = {\"top_k\": 200} # Send the message. response = bedrock_client.converse( modelId=model_id, messages=messages, system=system_prompts, inferenceConfig=inference_config, additionalModelRequestFields=additional_model_fields ) By changing model_id, you can switch between different models.\nI think AWS BedRock should have used the same standards as OpenAI’s client rather than creating their own But, hey, it’s still a single endpoint. right ?… I should be just able to switch models by changing model_id. right ?….\nHidden Gotcha of Converse API Not every model is available AWS BedRock has LLama3, Anthropic Claude, Mistral and their own Titan. But, It doesn’t have OpenAI models like GPT-4/GPT-4o. This might not be a deal breaker, depending on what you are trying to achieve. You can check the availability of models in AWS Bedrock Models\nNot every model has system prompt, or multi-modality support If you check converse API parameters, you will see that there is a parameter called system. This parameter is used to provide system prompt to the model. However, not every model supports system prompts. (Because they were not trained with system prompts). If you’re switching between models via code using ENV/Flags/Config, you might need to handle edge cases where a system prompt is unavailable for the given modelId. Otherwise, It will throw an Exception. (Ideally, i think it should just give a warning) AWS has a nice table to check if given model has system prompt.\nThe same goes for multi-modality. If your messages include images, switching between models might not be straightforward.\nNot every model has same context window I mean this is on you, but again good reminder.\nAdvance Prompt technique like Prefilling Assistant Message # code copied from https://eugeneyan.com//writing/prompting/#prefill-claudes-responses input = \"\"\" The SmartHome Mini is a compact smart home assistant available in black or white for only $49.99. At just 5 inches wide, it lets you control lights, thermostats, and other connected devices via voice or app—no matter where you place it in your home. This affordable little hub brings convenient hands-free control to your smart devices. Extract the , , , and from this product . Return the extracted attributes within . \"\"\" messages=[ { \"role\": \"user\", \"content\": input, }, { \"role\": \"assistant\", \"content\": \"\" # Prefilled response } ] # raise error_class(parsed_response, operation_name) # botocore.errorfactory.ValidationException: An error occurred (ValidationException) when calling the Converse # operation: The model that you are using requires the last turn in the conversation to be a user message. Add a # user message to the conversation and try again. If you’re using advanced prompting techniques, such as Prefilling Assistant Messages [3], where you pre-populate the message with text designated as ‘assistant’, you need to be cautious when switching between models. Not all models are compatible with this technique and their is validation check which will raise exception.\nSo, Overall, We are still far away from having a unified API for all models. I will update this article if i find anything new.\nReferences [1] https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html\n[2] https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-supported-models-features\n[3] https://eugeneyan.com//writing/prompting/#prefill-claudes-responses\n",
  "wordCount" : "654",
  "inLanguage": "en",
  "image": "https://dipkumar.dev/images/papermod-cover.png","datePublished": "2024-06-13T23:15:53+05:30",
  "dateModified": "2024-06-13T23:15:53+05:30",
  "author":{
    "@type": "Person",
    "name": "Dipkumar Patel"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://dipkumar.dev/posts/aws-bedrock/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Dip'Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://dipkumar.dev/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://dipkumar.dev/" accesskey="h" title="Dip&#39;Blog (Alt + H)">Dip&#39;Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://dipkumar.dev/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://dipkumar.dev/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://dipkumar.dev/tags/" title="tags">
                    <span>tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      AWS BedRock - Converse API - A single endpoint for all models ?
    </h1>
    <div class="post-meta"><span title='2024-06-13 23:15:53 +0530 IST'> June 13, 2024</span>&nbsp;|&nbsp;Estimated Reading Time: 4 min&nbsp;|&nbsp;
Author:
Dipkumar Patel&nbsp;|&nbsp;<a href="https://github.com/adityatelange/hugo-PaperMod/tree/exampleSite/content/posts/aws-bedrock.md" rel="noopener noreferrer" target="_blank">Suggest Changes</a>

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#hidden-gotcha-of-converse-api" aria-label="Hidden Gotcha of Converse API">Hidden Gotcha of Converse API</a><ul>
                        
                <li>
                    <a href="#not-every-model-is-available" aria-label="Not every model is available">Not every model is available</a></li>
                <li>
                    <a href="#not-every-model-has-system-prompt-or-multi-modality-support" aria-label="Not every model has system prompt, or multi-modality support">Not every model has system prompt, or multi-modality support</a></li>
                <li>
                    <a href="#not-every-model-has-same-context-window" aria-label="Not every model has same context window">Not every model has same context window</a></li>
                <li>
                    <a href="#advance-prompt-technique-like-prefilling-assistant-message" aria-label="Advance Prompt technique like Prefilling Assistant Message">Advance Prompt technique like Prefilling Assistant Message</a></li></ul>
                </li>
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>Amazon Bedrock is a fully managed service that makes high-performing foundation models (FMs) from leading AI startups and Amazon available for your use through a unified API. You can choose from a wide range of foundation models to find the model that is best suited for your use case. Amazon Bedrock also offers a broad set of capabilities to build generative AI applications with security, privacy, and responsible AI. With Amazon Bedrock, you can easily experiment with and evaluate top foundation models for your use cases, privately customize them with your data using techniques such as fine-tuning and Retrieval Augmented Generation (RAG), and build agents that execute tasks using your enterprise systems and data sources. [1]</p>
<p>AWS BedRock&rsquo;s Converse API is a single endpoint that allows you to chat with any model. Indeed, <strong>the single endpoint</strong> is, I believe, the best feature of AWS BedRock. Let&rsquo;s visit this endpoint and see how it works.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">model_id</span> <span class="o">=</span> <span class="s2">&#34;anthropic.claude-3-sonnet-20240229-v1:0&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">inference_config</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;temperature&#34;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="n">additional_model_fields</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;top_k&#34;</span><span class="p">:</span> <span class="mi">200</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Send the message.</span>
</span></span><span class="line"><span class="cl"><span class="n">response</span> <span class="o">=</span> <span class="n">bedrock_client</span><span class="o">.</span><span class="n">converse</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">modelId</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">system</span><span class="o">=</span><span class="n">system_prompts</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">inferenceConfig</span><span class="o">=</span><span class="n">inference_config</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">additionalModelRequestFields</span><span class="o">=</span><span class="n">additional_model_fields</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><p>By changing <code>model_id</code>, you can switch between different models.</p>
<p>I think AWS BedRock should have used the same standards as OpenAI&rsquo;s client rather than creating their own
But, hey, it&rsquo;s still a single endpoint. right ?&hellip;
I should be just able to switch models by changing model_id. right ?&hellip;.</p>
<p><img loading="lazy" src="https://i.imgflip.com/5bgun8.jpg?a477264=400x400" alt="AWS BedRock Endpoint"  />
</p>
<h2 id="hidden-gotcha-of-converse-api">Hidden Gotcha of Converse API<a hidden class="anchor" aria-hidden="true" href="#hidden-gotcha-of-converse-api">#</a></h2>
<h3 id="not-every-model-is-available">Not every model is available<a hidden class="anchor" aria-hidden="true" href="#not-every-model-is-available">#</a></h3>
<p>AWS BedRock has LLama3, Anthropic Claude, Mistral and their own Titan. But, It doesn&rsquo;t have OpenAI models like GPT-4/GPT-4o. This might not be a deal breaker, depending on what you are trying to achieve.
You can check the availability of models in <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html">AWS Bedrock Models</a></p>
<h3 id="not-every-model-has-system-prompt-or-multi-modality-support">Not every model has system prompt, or multi-modality support<a hidden class="anchor" aria-hidden="true" href="#not-every-model-has-system-prompt-or-multi-modality-support">#</a></h3>
<p>If you check converse API parameters, you will see that there is a parameter called <code>system</code>. This parameter is used to provide system prompt to the model. However, not every model supports system prompts. (Because they were not trained with system prompts). If you&rsquo;re switching between models via code using ENV/Flags/Config, you might need to handle edge cases where a system prompt is unavailable for the given <code>modelId</code>. Otherwise, It will throw an Exception. (Ideally, i think it should just give a warning)
AWS has a <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-supported-models-features">nice table</a> to check if given model has system prompt.</p>
<p>The same goes for multi-modality. If your messages include images, switching between models might not be straightforward.</p>
<h3 id="not-every-model-has-same-context-window">Not every model has same context window<a hidden class="anchor" aria-hidden="true" href="#not-every-model-has-same-context-window">#</a></h3>
<p>I mean this is on you, but again good reminder.</p>
<h3 id="advance-prompt-technique-like-prefilling-assistant-message">Advance Prompt technique like Prefilling Assistant Message<a hidden class="anchor" aria-hidden="true" href="#advance-prompt-technique-like-prefilling-assistant-message">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># code copied from https://eugeneyan.com//writing/prompting/#prefill-claudes-responses</span>
</span></span><span class="line"><span class="cl"><span class="nb">input</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">&lt;description&gt;
</span></span></span><span class="line"><span class="cl"><span class="s2">The SmartHome Mini is a compact smart home assistant available in black or white for 
</span></span></span><span class="line"><span class="cl"><span class="s2">only $49.99. At just 5 inches wide, it lets you control lights, thermostats, and other 
</span></span></span><span class="line"><span class="cl"><span class="s2">connected devices via voice or app—no matter where you place it in your home. This 
</span></span></span><span class="line"><span class="cl"><span class="s2">affordable little hub brings convenient hands-free control to your smart devices.
</span></span></span><span class="line"><span class="cl"><span class="s2">&lt;/description&gt;
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">Extract the &lt;name&gt;, &lt;size&gt;, &lt;price&gt;, and &lt;color&gt; from this product &lt;description&gt;.
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">Return the extracted attributes within &lt;attributes&gt;.
</span></span></span><span class="line"><span class="cl"><span class="s2">&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">messages</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;user&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="nb">input</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">},</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;assistant&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;attributes&gt;&lt;name&gt;&#34;</span>  <span class="c1"># Prefilled response</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="c1"># raise error_class(parsed_response, operation_name)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># botocore.errorfactory.ValidationException: An error occurred (ValidationException) when calling the Converse  </span>
</span></span><span class="line"><span class="cl"><span class="c1"># operation: The model that you are using requires the last turn in the conversation to be a user message. Add a </span>
</span></span><span class="line"><span class="cl"><span class="c1"># user message to the conversation and try again.</span>
</span></span></code></pre></div><p>If you&rsquo;re using advanced prompting techniques, such as Prefilling Assistant Messages [3], where you pre-populate the message with text designated as &lsquo;assistant&rsquo;, you need to be cautious when switching between models. Not all models are compatible with this technique and their is validation check which will raise exception.</p>
<p>So, Overall, We are still far away from having a unified API for all models. I will update this article if i find anything new.</p>
<h2 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h2>
<p>[1] <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html">https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html</a></p>
<p>[2] <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-supported-models-features">https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-supported-models-features</a></p>
<p>[3] <a href="https://eugeneyan.com//writing/prompting/#prefill-claudes-responses">https://eugeneyan.com//writing/prompting/#prefill-claudes-responses</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://dipkumar.dev/tags/llm/">Llm</a></li>
      <li><a href="https://dipkumar.dev/tags/ai/">Ai</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="https://dipkumar.dev/">Dip&#39;Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
